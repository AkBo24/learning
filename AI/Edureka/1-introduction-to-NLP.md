# Text Mining & NLP
### What is Text Mining / Text Analytics
Process of extracting patterns and information from **natural language text** (natural->generated by humans)
- text data is unstructured
- **goal: convert text into data for analysis**

Text mining is the intersection of Linguistics, Computer Science, and Mathematics
- engineers develop algorithms to extract info from large amounts of data
# What is NLP
**Natural Language Processing**
###### Basic Structure of an NLP App (Ex chatbot)
- application hosts a chat bot which is an interface for an NLP Layer
- every request to the chat bot queries an attached Knowledge Base and can interact with some data storage (which may host interaction history, interaction analytics etc)
### Some Applications of NLP
###### 1. Speech Recognition
###### 2. Text Classification
Process of assigning tags/categories to documents
- efficient way of adding structure to natural language

Fundamental task in NLP, helpful for sentiment analysis, spam detection etc
###### 3. Caption Generation
###### 4. Machine Translation
Translating language from one form to another
- ie language to language like google translate
###### 5. Messaging Bots
# Tokenization in NLP
First step in processing data
- process of decomposing text string into small structures or units called a **"token"**
- the unit for a token can change (words, characters, sentences, etc) depending on the program
- some tokens are reserved for special purposes (eg delimiters like a space or terminators like a period)

Ex:
- input string: ` "The blue boy runs."`
- output tokens: `[the, blue, boy, runs, .]`
# Text preprocessing, Dimension Reduction
Before tokenization, its common too **pre-process** the data
- one step **may** include removing grammar (generally grammar effects the connotation of the sentence not the meaning)
- fix spelling errors etc

We may remove words like "the" during tokenization to reduce the processing time
- other words called **stop word removals** may be filtered
	- this is a list of words in Natural Language Toolkit for 17 languages that are not important

Removing tokens like grammar or the stop words reduces the dimension of the text
- removing data to "simpler" forms that retains the meaningful properties of the original data (see dimensionality reduction in techniques like PCA)
# Text Processing Methods
##### Stemming
Process of extracting root words by eliminating the suffixes of input strings

Ex:
- input: `I like helping other people. My friend Jack helps me. Some seniors are helped by organizations like mine.`
- output: `helping, helps, and helped -> help` all have the root word "help")

However, stemming may over eliminate suffixes; for example, `beautiful` may become `beauti` which is not a root word.
##### Point of Speech (POS) Tagging
Process of tagging each work with the appropriate part of speech
- POS Tagging adds structure to data
- also provides context for stemming or lemmatization
	- for example, if we stem multiple words into `"help"`, the POS contextualizes `"help, verb" to "helps"`

Ex:
- input: `the boy runs`
- output: `[the -> article, boy -> subject, runs -> verb]`
##### Lemmatization
This process analyzes the context of a token to reduce it to the correct base representation called the **lemma**
- this technique improves language representation by encoding the grammatical category and tenses
- requires POS Tagging
- requires a dictionary to reference the correctness of a lemma

For example,
- "Saw" can be returned as "see" or "saw" depending if the input was a noun or verb
- "requirement" and "required" would return separate lemmas

Lemmatization reduces ambiguity; improves accuracy, contextualization, and language/grammar contextualization

However, it adds computational complexity and is more language dependent 
##### Named Entity Recognition (NER)
Process of finding the type of noun used (eg, a person's name, an animals name, etc name are all nouns)
- POS Tagging is a necessary prerequisite
- critical but challenging for many problems
