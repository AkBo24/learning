{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c88c02-07d2-4e2c-bb7d-84ce9a572f03",
   "metadata": {},
   "source": [
    "# A Quick Machine Learning Modelling Tutorial with Python and Scikit-Learn\n",
    "\n",
    "#### Resources\n",
    "- https://github.com/mrdbourke/zero-to-mastery-ml/blob/81492352d12d7a52caef57bba7744cbdc34af33f/section-2-data-science-and-ml-tools/introduction-to-scikit-learn.ipynb\n",
    "\n",
    "## Overview\n",
    "[Scikit-Learn](https://scikit-learn.org) (`sklearn`) is an open-sourced, Python, ML library built on NumPy and Matplotlib.\n",
    "- provides many utilities for common ML activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "708d7596-2d5d-4f77-a16a-08fe24a82edd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3b9603-91f5-4370-83a6-859ae3406e35",
   "metadata": {},
   "source": [
    "### End-to-end Scikit-learn Workflow\n",
    "> **note**: this notebook is focused on supervised learning\n",
    "\n",
    " 1. Prepare data (cleaning, split into features & labels, split into training and testing, etc.)\n",
    " 2. Choose the right model (linear regression, k-means, classification, etc.)\n",
    " 3. Fit the model to the data and use it to make predictions\n",
    " 4. Evaluate the model (and iterate!)\n",
    " 5. Prepare for deployment & sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1bc9e7-2740-4d96-b81b-276f063f9002",
   "metadata": {},
   "source": [
    "## 1. Prepare Data\n",
    "\n",
    "The main data transformation actions you'll have to take are:\n",
    "- splitting data columns into features & labesl (often labelled `X` and `Y`)\n",
    "- splitting the data records into test, validation, and training subsets\n",
    "- filling (aka imputing) or dropping missing values\n",
    "- converting non-numerical data into a numerical format (**feature-encoding**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9ee4700-e981-4f59-be3c-832bb73d3994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((303, 14), (242, 13), (61, 13), (242,), (61,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease = pd.read_csv(\"https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/master/data/heart-disease.csv\") # load data directly from URL (requires raw form on GitHub, source: https://github.com/mrdbourke/zero-to-mastery-ml/blob/master/data/heart-disease.csv)\n",
    "X = heart_disease.drop('target', axis=1)\n",
    "Y = heart_disease['target']\n",
    "\n",
    "# splitting data into training, testing, and potentially validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "heart_disease.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d0c120-83bb-40e5-aec6-486d04d6f6e2",
   "metadata": {},
   "source": [
    "## 1.1 Encoding Values\n",
    "\n",
    "All data must be in a numerical format. We can **encode** non-numerical (categorical) data using preprocessing techniques like `OneHotEncoding`:\n",
    "\n",
    "| Color |\n",
    "| --- |\n",
    "| Red |\n",
    "| Red |\n",
    "| Yellow |\n",
    "| Green |\n",
    "| Yellow |\n",
    "\n",
    "becomes\n",
    "\n",
    "| Red | Yellow | Green |\n",
    "| --- | --- | --- |\n",
    "| 1 | 0 | 0 |\n",
    "| 1 | 0 | 0 |\n",
    "| 0 | 1 | 0 |\n",
    "| 0 | 0 | 1 |\n",
    "| 0 | 1 | 0 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc818886-e0b6-4226-9aa6-49240154856d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 3.54310e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        1.00000e+00, 1.92714e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 8.47140e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 6.66040e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.15883e+05],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.48360e+05]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales = pd.read_csv(\"https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/master/data/car-sales-extended.csv\")\n",
    "car_sales.head\n",
    "\n",
    "# Split into X & y and train/test\n",
    "X = car_sales.drop(\"Price\", axis=1)\n",
    "y = car_sales[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define the categorical features to transform\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# Create an instance of a transformer using the OneHotMethod\n",
    "transformer = ColumnTransformer([(\"one hot\",\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                                remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03df6d90-5f02-4a67-a18d-dd51f8c3e5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3235867221569877"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a model using the encoded features\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dee04f-7d8e-4636-9623-896bceb0144f",
   "metadata": {},
   "source": [
    "# 1.2 Handling missing values\n",
    "\n",
    "There are two main options for handling missing values in data:\n",
    "\n",
    "1. **Imputation**: Fill missing values with a given or calculated value. The practice of calculating or figuring out how to fill missing values in a dataset is called imputing. See (Scikit-Learn user guide)[https://scikit-learn.org/stable/modules/impute.html] for resources on imputing missing values.\n",
    "2. **Remove them**: Remove the records from the dataset, however, this decreases the amount of data the model has to train and validate from.\n",
    "\n",
    "Dealing with missing values depends on the problem, the dataset, and other factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1002ab-02ff-4718-9424-671c56caa0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing = pd.read_csv(\"https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/master/data/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b41aa1-4f36-4e0c-a11a-e240906d3263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features and labels\n",
    "X_missing = car_sales_missing.drop(\"Price\", axis=1)\n",
    "print(f\"Number of missing X values:\\n{X_missing.isna().sum()}\")\n",
    "y_missing = car_sales_missing[\"Price\"]\n",
    "print(f\"Number of missing y values: {y_missing.isna().sum()}\")\n",
    "\n",
    "# encode categorical data & apply the transformation\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTrasformer(\n",
    "    [(\"one hot\", one_hot, categorical_features)],\n",
    "    remainder=\"passthrough\",\n",
    "    sparse_threshold = 0\n",
    ")\n",
    "\n",
    "transformed_X_missing = transformer.fit_transform(X_missing)\n",
    "\n",
    "# Create training & split subdatasets, fit, & score a model\n",
    "X_train, X_missing, y_train, y_test = train_test_split(trasnformed_X_missing, y_missing, test_size = 0.2)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
