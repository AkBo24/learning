{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c88c02-07d2-4e2c-bb7d-84ce9a572f03",
   "metadata": {},
   "source": [
    "# A Quick Machine Learning Modelling Tutorial with Python and Scikit-Learn\n",
    "\n",
    "#### Resources\n",
    "- https://github.com/mrdbourke/zero-to-mastery-ml/blob/81492352d12d7a52caef57bba7744cbdc34af33f/section-2-data-science-and-ml-tools/introduction-to-scikit-learn.ipynb\n",
    "\n",
    "## Overview\n",
    "[Scikit-Learn](https://scikit-learn.org) (`sklearn`) is an open-sourced, Python, ML library built on NumPy and Matplotlib.\n",
    "- provides many utilities for common ML activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "708d7596-2d5d-4f77-a16a-08fe24a82edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3b9603-91f5-4370-83a6-859ae3406e35",
   "metadata": {},
   "source": [
    "### End-to-end Scikit-learn Workflow\n",
    "> **note**: this notebook is focused on supervised learning\n",
    "\n",
    " 1. Prepare data (cleaning, split into features & labels, split into training and testing, etc.)\n",
    " 2. Choose the right model (linear regression, k-means, classification, etc.)\n",
    " 3. Fit the model to the data and use it to make predictions\n",
    " 4. Evaluate the model (and iterate!)\n",
    " 5. Prepare for deployment & sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1bc9e7-2740-4d96-b81b-276f063f9002",
   "metadata": {},
   "source": [
    "## 1. Prepare Data\n",
    "\n",
    "The main data transformation actions you'll have to take are:\n",
    "- splitting data columns into features & labesl (often labelled `X` and `Y`)\n",
    "- splitting the data records into test, validation, and training subsets\n",
    "- filling (aka imputing) or dropping missing values\n",
    "- converting non-numerical data into a numerical format (**feature-encoding**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9ee4700-e981-4f59-be3c-832bb73d3994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((303, 14), (242, 13), (61, 13), (242,), (61,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease = pd.read_csv(\"https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/master/data/heart-disease.csv\") # load data directly from URL (requires raw form on GitHub, source: https://github.com/mrdbourke/zero-to-mastery-ml/blob/master/data/heart-disease.csv)\n",
    "X = heart_disease.drop('target', axis=1)\n",
    "Y = heart_disease['target']\n",
    "\n",
    "# splitting data into training, testing, and potentially validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "heart_disease.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d0c120-83bb-40e5-aec6-486d04d6f6e2",
   "metadata": {},
   "source": [
    "## 1.1 Encoding Values\n",
    "\n",
    "All data must be in a numerical format. We can **encode** non-numerical (categorical) data using preprocessing techniques like `OneHotEncoding`:\n",
    "\n",
    "| Color |\n",
    "| --- |\n",
    "| Red |\n",
    "| Red |\n",
    "| Yellow |\n",
    "| Green |\n",
    "| Yellow |\n",
    "\n",
    "becomes\n",
    "\n",
    "| Red | Yellow | Green |\n",
    "| --- | --- | --- |\n",
    "| 1 | 0 | 0 |\n",
    "| 1 | 0 | 0 |\n",
    "| 0 | 1 | 0 |\n",
    "| 0 | 0 | 1 |\n",
    "| 0 | 1 | 0 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc818886-e0b6-4226-9aa6-49240154856d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 3.54310e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        1.00000e+00, 1.92714e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 8.47140e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 6.66040e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.15883e+05],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 2.48360e+05]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales = pd.read_csv(\"https://raw.githubusercontent.com/mrdbourke/zero-to-mastery-ml/master/data/car-sales-extended.csv\")\n",
    "car_sales.head\n",
    "\n",
    "# Split into X & y and train/test\n",
    "X = car_sales.drop(\"Price\", axis=1)\n",
    "y = car_sales[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define the categorical features to transform\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# Create an instance of a transformer using the OneHotMethod\n",
    "transformer = ColumnTransformer([(\"one hot\",\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                                remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03df6d90-5f02-4a67-a18d-dd51f8c3e5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3235867221569877"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a model using the encoded features\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
